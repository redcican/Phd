{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc396fd-7155-4e2b-b9c8-3b40ab7f5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import truncnorm\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#\n",
    "import xgboost as xgb\n",
    "#\n",
    "#\n",
    "import nevergrad as ng\n",
    "# import autograd.numpy as au\n",
    "# from autograd import grad, jacobian\n",
    "#\n",
    "from concurrent import futures\n",
    "import time\n",
    "import os\n",
    "#\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import minimize\n",
    "#\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6edb7d3-34e0-4ff7-a53f-46c5fd8d9809",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e1e977f-b563-4a4a-b7c0-ccbe41b7dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(1234)\n",
    "np.random.seed(42)\n",
    "n_list = [10,15]\n",
    "m_list = [5]\n",
    "budget = {'default':20}#, (10,5):200, (15,5):150, (15,10):100}\n",
    "maxiter = 350\n",
    "K = 35\n",
    "constraint_tolerance = .01\n",
    "opt_list = [ng.optimizers.NGOpt, ng.optimizers.NGOptRW]#, ng.optimizers.NelderMead, ng.optimizers.Cobyla]\n",
    "filename = \"results_rw_n15_m10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f2345ae-4ceb-480b-b4de-04b559f59af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, n):\n",
    "    sum = 0.0\n",
    "    for i in range(n-1):\n",
    "        a = 100 * ((x[i+1] -x[i]**2)**2)\n",
    "        b = (1 - x[i])**2\n",
    "        sum += a+b\n",
    "    return sum\n",
    "\n",
    "def get_truncated_normal(mean=5, sd=1, low=0, upp=10, size=None):\n",
    "    \"\"\"normal distribution between 0 and 10\"\"\"\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd).rvs(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "639ffb77-018e-4b32-95f9-4e2e7ffacb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_constants(k:int, mean=5., sd=1., seed=42, low=0, upp=10):\n",
    "    np.random.seed(seed)\n",
    "    return get_truncated_normal(size=k, mean=mean, sd=sd, low=low, upp=upp)\n",
    "\n",
    "def get_random_indices(n:int, seed:int=42):\n",
    "    indices = np.arange(n)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    return indices\n",
    "\n",
    "def fill_with_constants(x:np.array, constants:np.array, indices:np.array):\n",
    "    #return np.append(x,constants)[indices]\n",
    "    return np.take(np.append(x,constants), indices)\n",
    "\n",
    "def fill_with_constants_tf(x, constants:np.array, indices:np.array):\n",
    "    y = tf.concat([x,constants], axis=-1)\n",
    "    return tf.gather(y, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b67e5c5-7811-426d-87f2-95e58f9e14e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 values:\n",
      "\n",
      "n=10\n",
      "ANN: -12.116\n",
      "XGB: 0.9726\n",
      "\n",
      "\n",
      "n=15\n",
      "ANN: -18.0735\n",
      "XGB: 0.9553\n",
      "\n",
      "\n",
      "{10: <keras.engine.sequential.Sequential object at 0x7fb6d68ee730>, 15: <keras.engine.sequential.Sequential object at 0x7fb71403fcd0>}\n"
     ]
    }
   ],
   "source": [
    "ann_models = {n: tf.keras.models.load_model(f\"models/ANN_{n}\") for n in n_list}\n",
    "xgb_models = {n: xgb.Booster() for n in n_list}\n",
    "for n in n_list:\n",
    "    xgb_models[n].load_model(f\"models/XGB_{n}.json\")\n",
    "#\n",
    "with open('models/metadata.json', 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "#\n",
    "print(\"R^2 values:\\n\")\n",
    "for n in metadata.keys():\n",
    "    print(f\"n={n}\")\n",
    "    print(f\"ANN: {round(metadata[n]['ANN_R2'],4)}\\nXGB: {round(metadata[n]['XGB_R2'],4)}\")\n",
    "    print(\"\\n\")\n",
    "print(ann_models)\n",
    "#print(xgb_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e8ced-766d-4760-90a6-7f14efa81d83",
   "metadata": {},
   "source": [
    "## Models and objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c7470b2-d35d-4e7a-b175-34e5cf828dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def get_functions(n, constants, indices):\n",
    "    #\n",
    "    weights = ann_models[n].get_weights()\n",
    "    def f_ann(x):\n",
    "        x1 = fill_with_constants(x, constants, indices)\n",
    "        z1 = np.dot(x1, weights[0]) + weights[1]\n",
    "        a1 = relu(z1)\n",
    "        z2 = np.dot(a1, weights[2]) + weights[3]\n",
    "        a2 = relu(z2)\n",
    "        z3 = np.dot(a2, weights[4]) + weights[5]\n",
    "        return z3\n",
    "    #\n",
    "    #grad_f_ann = grad(f_ann)\n",
    "    #\n",
    "    def f_ann_tf(x):\n",
    "        x1 = fill_with_constants_tf(x, constants, indices)\n",
    "        x2 = tf.convert_to_tensor([x1])\n",
    "        x2 = tf.cast(x2,dtype=tf.float32)\n",
    "        return ann_models[n](x2)[0]\n",
    "    #\n",
    "    def grad_f_ann_tf(x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x)\n",
    "            t2 = f_ann_tf(x)\n",
    "            y = tape.jacobian(t2, x)\n",
    "            return y\n",
    "        \n",
    "    def hess_tf(x):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x)\n",
    "            t2 = f_ann_tf(x)\n",
    "            y = tape.gradient(t2, x)\n",
    "            h = tape.jacobian(y, x)\n",
    "            return y, h\n",
    "    #\n",
    "    def f_xgb(x):\n",
    "        x1 = fill_with_constants(x, constants, indices)\n",
    "        y = xgb_models[n].predict(xgb.DMatrix([x1]))#x1.reshape(1,-1))\n",
    "        return y.item()\n",
    "    #\n",
    "    def f_rosen(x):\n",
    "        x1 = fill_with_constants(x, constants, indices)\n",
    "        return rosenbrock(x1, n)\n",
    "    #\n",
    "    return f_rosen, f_ann_tf, grad_f_ann_tf, f_xgb, hess_tf\n",
    "    #return f_rosen, f_ann, grad_f_ann, f_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6f92e-6141-4540-975b-104325464532",
   "metadata": {},
   "source": [
    "## Optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5072349-b25b-4450-912c-0fbd2a4bebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ng(m, f, constraint_c, optclass, budget=1_000, x_start=None, constraint_tolerance=.1):\n",
    "    instrum = ng.p.Instrumentation(\n",
    "        ng.p.Array(shape=(m,)).set_bounds(lower=0.0, upper=10),\n",
    "    )\n",
    "    optimizer = optclass(parametrization=instrum, budget=budget, num_workers=1)\n",
    "    optimizer.parametrization.register_cheap_constraint(lambda x:np.sum(x[0]) - constraint_c)\n",
    "    optname = str(optclass).split(\".\")[-1].split(\"'\")[0]\n",
    "    filepath = f\"optimization/{optname}_logs.txt\"\n",
    "    optimizer.register_callback(\"tell\", ng.callbacks.ParametersLogger(filepath, append=False))\n",
    "    #\n",
    "    start = time.time()\n",
    "    recommendation = optimizer.minimize(f, verbosity=0, batch_mode=False)\n",
    "    #with futures.ThreadPoolExecutor(max_workers=optimizer.num_workers) as executor:\n",
    "    #    recommendation = optimizer.minimize(f, verbosity=0, executor=executor, batch_mode=False)\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    #\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        log = [ast.literal_eval(line) for line in lines]\n",
    "    #\n",
    "    ## select argument with minimum function value satisfying the constraint\n",
    "    x_list = [l['0'] for l in log]\n",
    "    x_constrained_list = [x for x in x_list if np.abs((np.sum(x)-constraint_c))/constraint_c < constraint_tolerance]\n",
    "    #x_constrained_list = x_constrained_list or x_list\n",
    "    if not x_constrained_list:\n",
    "        x_constrained_list = x_list\n",
    "        print(\"Could not satisfy constraints.\")\n",
    "    loss_array = np.array([f(x) for x in x_constrained_list])\n",
    "    min_index = loss_array.argmin()\n",
    "    x_min = x_constrained_list[min_index]\n",
    "    #\n",
    "    #return np.asarray(recommendation.value)[0][0], elapsed_time\n",
    "    return np.asarray(x_min), elapsed_time\n",
    "\n",
    "\n",
    "def optimize_grad(m, f, grad_f, constraint_c, maxiter=maxiter, x_start=None):\n",
    "    if x_start is None: x_start = np.ones(m)\n",
    "    eq_cons = {'type': 'eq',\n",
    "               'fun' : lambda x:np.sum(x)-constraint_c\n",
    "               }\n",
    "    bounds = Bounds([0.0]*m, [10.0]*m)\n",
    "    start = time.time()\n",
    "    result = minimize(fun=f, x0=x_start, jac=grad_f,constraints=[eq_cons], method='SLSQP',\n",
    "    options={'ftol': 1e-12, 'disp': False, 'maxiter':maxiter}, bounds=bounds)\n",
    "    end = time.time()\n",
    "    #\n",
    "    elapsed_time = end - start\n",
    "    return result.x, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03740ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=15\n",
    "m=10\n",
    "constants = get_random_constants(n-m, seed=seed)\n",
    "indices = get_random_indices(n, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5829b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rosen, f_ann, grad_f_ann,f_xgb, hess_tf = get_functions(n, constants, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a0a2a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Converting IndexedSlices(indices=Tensor(\"gradient_tape/sub_2:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/GatherV2_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/Shape_5:0\", shape=(1,), dtype=int32)) to a dense representation may make it slow. Alternatively, output the indices and values of the IndexedSlices separately, and handle the vectorized outputs directly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.framework.indexed_slices.IndexedSlices at 0x7fb6d6459970>,\n",
       " <tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       " array([[-0.04190152, -0.04610078, -0.02778385, -0.02734154, -0.04667171,\n",
       "         -0.0262934 , -0.02368741, -0.03795334, -0.02840973, -0.01509296],\n",
       "        [-0.04610078, -0.09451991, -0.01778026, -0.03560251, -0.07787273,\n",
       "         -0.04970959, -0.03674165, -0.04405955, -0.05158599, -0.01428949],\n",
       "        [-0.02778385, -0.01778027, -0.0347028 , -0.01835832, -0.02983059,\n",
       "         -0.01679232, -0.01171066, -0.01387203, -0.01398957, -0.01063736],\n",
       "        [-0.02734154, -0.03560251, -0.01835832, -0.04595041, -0.03500346,\n",
       "         -0.0279151 , -0.02116625, -0.03274539, -0.02161375, -0.00885629],\n",
       "        [-0.0466717 , -0.07787275, -0.02983058, -0.03500344, -0.09491346,\n",
       "         -0.04584476, -0.03788688, -0.05668491, -0.05215588, -0.0250662 ],\n",
       "        [-0.02629339, -0.04970958, -0.01679232, -0.02791509, -0.04584478,\n",
       "         -0.04117362, -0.03196042, -0.03522967, -0.03058466, -0.017358  ],\n",
       "        [-0.02368742, -0.03674165, -0.01171066, -0.02116624, -0.03788686,\n",
       "         -0.03196041, -0.03805   , -0.0246109 , -0.02923018, -0.01928943],\n",
       "        [-0.03795336, -0.04405955, -0.01387202, -0.03274538, -0.0566849 ,\n",
       "         -0.03522968, -0.0246109 , -0.05473657, -0.03118331, -0.02728411],\n",
       "        [-0.02840972, -0.051586  , -0.01398957, -0.02161375, -0.05215589,\n",
       "         -0.03058466, -0.02923017, -0.03118331, -0.05558097, -0.02292452],\n",
       "        [-0.01509296, -0.01428949, -0.01063736, -0.00885629, -0.02506619,\n",
       "         -0.017358  , -0.01928943, -0.02728411, -0.02292452, -0.03337196]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hess_tf = tf.function(hess_tf)\n",
    "hess_tf(tf.random.normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139e2dca-89cf-40b2-b106-aa059eb30cce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for n=15 and m=10, trial 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cican/miniconda3/lib/python3.9/site-packages/nevergrad/parametrization/core.py:332: UserWarning: Lambda as constraint is not advised because it may not be picklable.\n",
      "  warnings.warn(\"Lambda as constraint is not advised because it may not be picklable.\")\n",
      "/home/cican/miniconda3/lib/python3.9/site-packages/nevergrad/optimization/recaster.py:272: FinishedUnderlyingOptimizerWarning: Underlying optimizer has already converged, returning random points\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not satisfy constraints.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cican/miniconda3/lib/python3.9/site-packages/nevergrad/parametrization/core.py:332: UserWarning: Lambda as constraint is not advised because it may not be picklable.\n",
      "  warnings.warn(\"Lambda as constraint is not advised because it may not be picklable.\")\n",
      "/home/cican/miniconda3/lib/python3.9/site-packages/nevergrad/optimization/recaster.py:272: FinishedUnderlyingOptimizerWarning: Underlying optimizer has already converged, returning random points\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_minimize_trustregion_constr() got an unexpected keyword argument 'ftol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m     results_current[optname][\u001b[39m'\u001b[39m\u001b[39mbudget\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m current_budget\n\u001b[1;32m     28\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m x_min_ann, elapsed_time_ann \u001b[39m=\u001b[39m optimize_grad(m, f_ann, grad_f_ann, hess_tf,constraint_c)\n\u001b[1;32m     30\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     31\u001b[0m y_min_ann \u001b[39m=\u001b[39m f_rosen(x_min_ann)\n",
      "Cell \u001b[0;32mIn[16], line 44\u001b[0m, in \u001b[0;36moptimize_grad\u001b[0;34m(m, f, grad_f, hess_f, constraint_c, maxiter, x_start)\u001b[0m\n\u001b[1;32m     42\u001b[0m bounds \u001b[39m=\u001b[39m Bounds([\u001b[39m0.0\u001b[39m]\u001b[39m*\u001b[39mm, [\u001b[39m10.0\u001b[39m]\u001b[39m*\u001b[39mm)\n\u001b[1;32m     43\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 44\u001b[0m result \u001b[39m=\u001b[39m minimize(fun\u001b[39m=\u001b[39;49mf, x0\u001b[39m=\u001b[39;49mx_start, jac\u001b[39m=\u001b[39;49mgrad_f, hess\u001b[39m=\u001b[39;49mhess_f,constraints\u001b[39m=\u001b[39;49m[eq_cons], method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrust-constr\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     45\u001b[0m options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mftol\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m1e-12\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdisp\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m'\u001b[39;49m:maxiter}, bounds\u001b[39m=\u001b[39;49mbounds)\n\u001b[1;32m     46\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     47\u001b[0m \u001b[39m#\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:704\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    701\u001b[0m     res \u001b[39m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[1;32m    702\u001b[0m                           constraints, callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    703\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrust-constr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 704\u001b[0m     res \u001b[39m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    705\u001b[0m                                        bounds, constraints,\n\u001b[1;32m    706\u001b[0m                                        callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    707\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdogleg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    708\u001b[0m     res \u001b[39m=\u001b[39m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001b[1;32m    709\u001b[0m                            callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "\u001b[0;31mTypeError\u001b[0m: _minimize_trustregion_constr() got an unexpected keyword argument 'ftol'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in n_list:\n",
    "    m_list_current = [m for m in m_list if m < n]\n",
    "    for m in m_list_current:\n",
    "        for k in range(K):\n",
    "            print(f\"Optimizing for n={n} and m={m}, trial {k+1}/{K}\")\n",
    "            #\n",
    "            seed = k + 1_000*n + 1_000_000*m\n",
    "            results_current = {'n': n, 'm': m, 'k': k}\n",
    "            constants = get_random_constants(n-m, seed=seed)\n",
    "            indices = get_random_indices(n, seed=seed)\n",
    "            constraint_c = 5*m\n",
    "            current_budget = budget.get((n,m), budget['default'])\n",
    "            #\n",
    "            f_rosen, f_ann, grad_f_ann,f_xgb = get_functions(n, constants, indices)\n",
    "            f_ann, grad_f_ann, hess_tf = tf.function(f_ann), tf.function(grad_f_ann)\n",
    "            #\n",
    "            x_min = {}\n",
    "            for optclass in opt_list:\n",
    "                optname = str(optclass).split(\".\")[-1].split(\"'\")[0]\n",
    "                results_current[optname] = {}\n",
    "                x_min, elapsed_time = optimize_ng(m, f_xgb, constraint_c, optclass=optclass, budget=current_budget, constraint_tolerance=constraint_tolerance, x_start=None)\n",
    "                y_min = f_rosen(x_min)\n",
    "                results_current[optname]['x_min'] = x_min.tolist()\n",
    "                results_current[optname]['time'] = elapsed_time\n",
    "                results_current[optname]['loss'] = y_min\n",
    "                results_current[optname]['budget'] = current_budget\n",
    "            #\n",
    "            x_min_ann, elapsed_time_ann = optimize_grad(m, f_ann, grad_f_ann, constraint_c)\n",
    "            #\n",
    "            y_min_ann = f_rosen(x_min_ann)\n",
    "            #\n",
    "            results_current['ann'] = {'loss': y_min_ann, 'time': elapsed_time_ann, 'x_min': x_min_ann.tolist()}\n",
    "            results.append(results_current)\n",
    "            #\n",
    "            with open(os.path.join('optimization', filename), 'w') as file:\n",
    "                json.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a569b7-b366-4de1-9235-cfda1743826d",
   "metadata": {},
   "source": [
    "## Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58dff1-8a09-4582-b261-a94c5ec2581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([r['NelderMead']['loss'] for r in results if r['n']==15 and r['m']==10])\n",
    "#print([r['ann']['loss'] for r in results if r['n']==15 and r['m']==10])\n",
    "#\n",
    "#print([np.sum(r['NelderMead']['x_min']) for r in results if r['n']==15 and r['m']==10])\n",
    "#print([np.sum(r['ann']['x_min']) for r in results if r['n']==15 and r['m']==10])\n",
    "#\n",
    "print([r['NelderMead']['loss'] for r in results if r['n']==10 and r['m']==5])\n",
    "print([r['ann']['loss'] for r in results if r['n']==10 and r['m']==5])\n",
    "#\n",
    "print([np.sum(r['NelderMead']['x_min']) for r in results if r['n']==10 and r['m']==5])\n",
    "print([np.sum(r['ann']['x_min']) for r in results if r['n']==10 and r['m']==5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adfa25-6125-4a17-8f12-8827c56296be",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=K-1\n",
    "n=15\n",
    "m=10\n",
    "seed = k + 1_000*n + 1_000_000*m\n",
    "results_current = {'n': n, 'm': m, 'k': k}\n",
    "constants = get_random_constants(n-m, seed=seed)\n",
    "indices = get_random_indices(n, seed=seed)\n",
    "constraint_c = 5*m\n",
    "#\n",
    "f_rosen, f_ann, grad_f_ann, f_xgb = get_functions(n, constants, indices)\n",
    "f_ann, grad_f_ann = tf.function(f_ann), tf.function(grad_f_ann)\n",
    "x_min_ann, elapsed_time_ann = optimize_grad(m, f_ann, grad_f_ann, constraint_c, maxiter=1e7)\n",
    "#\n",
    "y_min_ann = f_rosen(x_min_ann)\n",
    "results_current['ann'] = {'loss': y_min_ann, 'time': elapsed_time_ann, 'x_min': x_min_ann.tolist()}\n",
    "print(results_current)\n",
    "print(results_current['ann']['loss'])\n",
    "np.random.seed(16807)\n",
    "print([np.sum(r['NelderMead']['x_min']) for r in results if r['m']==10 and r['n']==15])\n",
    "print([r['NelderMead']['loss'] for r in results if r['m']==10 and r['n']==15])\n",
    "print(f_rosen(x_min_ann))#+0.01*np.random.uniform(size=m)))\n",
    "print(np.sum(x_min_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f813ce-05ef-409c-ae18-c7f094090f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('optimization/NelderMead_logs.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    log = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            log.append(ast.literal_eval(line))\n",
    "        except ValueError:\n",
    "            print(\"malformed string; skipping this line\")\n",
    "        except SyntaxError:\n",
    "            print(\"looks like some encoding errors with this file...\")\n",
    "#\n",
    "#print([np.sum(l['0']) for l in log])\n",
    "constraint_c = 50.\n",
    "constraint_tolerance = .1\n",
    "#\n",
    "x_list = [l['0'] for l in log]\n",
    "x_constrained_list = [x for x in x_list if np.abs((np.sum(x)-constraint_c))/constraint_c < constraint_tolerance]\n",
    "print([f_rosen(x) for x in x_constrained_list])\n",
    "loss_array = np.array([f_xgb(x) for x in x_constrained_list])\n",
    "min_index = loss_array.argmin()\n",
    "x_min_temp = x_constrained_list[min_index]\n",
    "print(np.sum(x_min_temp))\n",
    "print(f_rosen(x_min_temp))\n",
    "#print(min([f_xgb(l['0']) for l in log]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9db1a-1df7-47a9-a498-af4000c0ef35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
