{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141a58e5-ba30-45b3-87b7-0134221d3f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 18:09:38.907724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import truncnorm\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4111d60d-04b2-481e-bb51-8629539f2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed\n",
    "n_list = [10, 15]\n",
    "epochs = {\n",
    "    10: 1,\n",
    "    15: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c2080-28a2-4115-a229-2d12e67d77bb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pi(x_n) = \\sum_{i=1}^{n-1}\\, [100(x_{i+1}-x_{i}^2)^2 + (1 - x_i)^2]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e6e6de-8585-46ab-b14e-7b77f7f06f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, n):\n",
    "    sum = 0.0\n",
    "    for i in range(n-1):\n",
    "        a = 100 * ((x[i+1] -x[i]**2)**2)\n",
    "        b = (1 - x[i])**2\n",
    "        sum += a+b\n",
    "    return sum\n",
    "\n",
    "def get_truncated_normal(mean=5, sd=1, low=0, upp=10, size=None):\n",
    "    \"\"\"normal distribution between 0 and 10\"\"\"\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd).rvs(size)\n",
    "\n",
    "def generate_x(n, k):\n",
    "    \"\"\"\n",
    "    generate n dimensional normal distribution array in range [0, 10] (mit gaussian standard!!!)\n",
    "    n: how many columns to generate\n",
    "    k : how many rows to generate\n",
    "    \"\"\"\n",
    "    x = np.array([get_truncated_normal(size=k) for _ in range(n)])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595e7e4e-43d6-416f-a6d1-5914302b9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n, k=50_000, verbose=True):\n",
    "    X = generate_x(n=n, k=k)\n",
    "    y = rosenbrock(X, n)\n",
    "    columns_name = [f'x_{i}' for i in range(n)]\n",
    "    #\n",
    "    df = pd.DataFrame(X.T, columns=columns_name)\n",
    "    df[\"y\"] = y\n",
    "    #\n",
    "    if verbose:\n",
    "        df.head()\n",
    "        df.describe()\n",
    "    #\n",
    "    X = df.drop('y', axis = 1)\n",
    "    y = df['y']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c90ae8-8ab3-44a0-b120-68869b303284",
   "metadata": {},
   "source": [
    "## Train neural network and XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e104d8-a2db-4a49-bcaf-2012eca7a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_ann():\n",
    "    model = keras.Sequential([\n",
    "      layers.Dense(64, activation='tanh'), # tanh, sigmoid, R2 < 0, \n",
    "      layers.Dense(128, activation='tanh'),\n",
    "      layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model\n",
    "\n",
    "def train_ann(X_train, y_train, epochs):\n",
    "    ann_model = build_and_compile_ann()\n",
    "    history = ann_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        verbose=0, epochs=epochs)\n",
    "    return ann_model, history\n",
    "\n",
    "def train_xgb(X_train, y_train):\n",
    "    xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b5ae37-f2c1-4d44-944c-3af27225c92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for 10 variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 18:10:27.521186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 18:10:27.524176: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 18ms/step\n",
      "R2 score of ANN (10 variables):  -12.116012199700815\n",
      "R2 score of XGBoost (10 variables):  0.972556327033647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ANN_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ANN_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for 15 variables\n",
      "157/157 [==============================] - 3s 18ms/step\n",
      "R2 score of ANN (15 variables):  -18.073467568352996\n",
      "R2 score of XGBoost (15 variables):  0.9553017201951887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ANN_15/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ANN_15/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "metadata = {}\n",
    "for n in n_list:\n",
    "    X, y = create_data(n)\n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X, y, test_size=0.1)\n",
    "    X_train = X_df_train.values\n",
    "    y_train = y_df_train.values\n",
    "    #\n",
    "    print(f\"Training models for {n} variables\")\n",
    "    xgb_model = train_xgb(X_train, y_train)\n",
    "    ann_model, history = train_ann(X_train, y_train, epochs=epochs[n])\n",
    "    #\n",
    "    y_pred_ann = ann_model.predict(X_df_test)\n",
    "    y_pred_xgb = xgb_model.predict(X_df_test.values)\n",
    "    r2_ann = r2_score(y_df_test, y_pred_ann.flatten())\n",
    "    r2_xgb = r2_score(y_df_test, y_pred_xgb)\n",
    "    print(f\"R2 score of ANN ({n} variables): \", r2_ann)\n",
    "    print(f\"R2 score of XGBoost ({n} variables): \", r2_xgb)\n",
    "    #\n",
    "    metadata_n = {'ANN_R2': r2_ann, 'XGB_R2': r2_xgb, 'epochs': epochs[n]}\n",
    "    metadata[n] = metadata_n\n",
    "    #\n",
    "    ann_model.save(f'models/ANN_{n}')\n",
    "    xgb_model.save_model(f'models/XGB_{n}.json')\n",
    "\n",
    "with open('models/metadata.json', 'w') as file:\n",
    "    json.dump(metadata, file)\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ae7b7-9bbe-47cc-92a0-6250e0a2436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0, 200])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
