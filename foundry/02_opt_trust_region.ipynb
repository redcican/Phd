{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1d1552-6e43-4ad6-bade-d2e64d1bb648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 14:23:28.625591: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "import json\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import truncnorm\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#\n",
    "import xgboost as xgb\n",
    "#\n",
    "\n",
    "#\n",
    "from concurrent import futures\n",
    "import time\n",
    "#\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "\n",
    "\n",
    "#from more_itertools import grouper\n",
    "import cobyqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f9ddb-7c6b-4b82-ba1b-d00c02f3b6f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057c0cd9-f838-41df-8753-bfd42b3c1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(1234)\n",
    "np.random.seed(42)\n",
    "\n",
    "# chemical component to achieve: C 1,55 / Si 0,4 / Mn 0,3 / Cr 11,8 / Mo 0,75 / V 0,82\n",
    "chemi_component = (np.array([1.55,0.4,0.3,11.8,0.75,0.82]) / 100.0).astype(np.float32)\n",
    "\n",
    "chemi_names = ['C','Si','Mn','Cr','Mo','V']\n",
    "\n",
    "# total weight for the final steel production\n",
    "total_weight = 10_000\n",
    "\n",
    "total_chemi_to_achieve = total_weight * chemi_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af635519-4ead-4e07-8d5a-bd0edf71e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_12379.csv\")\n",
    "df_chemi = pd.read_excel(\"data/chemi.xlsx\", engine=\"openpyxl\")\n",
    "df_price = pd.read_excel(\"data/scrap.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ac9fd2-033e-42cc-86ed-6661e564aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return all information from df\n",
    "def df_columns_name(df):\n",
    "    columns = df.columns.tolist()\n",
    "    remove_columns = ['HeatID', 'HeatOrderID','Energy']\n",
    "    features_columns = [x for x in columns if x not in remove_columns]\n",
    "    \n",
    "    # constant process parameter, start with \"Feature\"\n",
    "    constant_features_names = [x for x in features_columns if \"Feature\" in x]\n",
    "    \n",
    "    #\"K\" means Kreislauf, \"L\" means Legierungen, \"F\" means Fremdschrotte, we only want to optimize \"F\"\n",
    "    schrotte_features_names = [x for x in features_columns if \"Feature\" not in x]\n",
    "    \n",
    "    # schrotte name for Kreislauf\n",
    "    kreislauf_schrotte_names = [x for x in features_columns if \"K\" in x]\n",
    "    \n",
    "    # schrotte name for legierung\n",
    "    legierung_schrotte_names = [x for x in features_columns if \"L\" in x]\n",
    "    \n",
    "    # schrotte name for Fremdschrotte\n",
    "    fremd_schrotte_names = [x for x in features_columns if \"F\" in x and len(x) < 4]\n",
    "    \n",
    "    return constant_features_names, schrotte_features_names, kreislauf_schrotte_names,legierung_schrotte_names,fremd_schrotte_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8efd873a-2bde-45a4-b61b-9ca772108239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the chemical component weights\n",
    "# randomly choose a row from df\n",
    "\n",
    "constant_features_names, schrotte_features_names, kreislauf_schrotte_names, legierung_schrotte_names,fremd_schrotte_names = df_columns_name(df)\n",
    "\n",
    "def calculate_chemi_component(df, df_chemi):\n",
    "    \n",
    "    \"\"\"\n",
    "    return the randomly chosen row, and its constant column, kreislauf column and \n",
    "    legierung column, use them to return the chemical component of fremdschrotte column\n",
    "    \"\"\"\n",
    "    df_random_row = df.sample()\n",
    "    \n",
    "    # calculate the constant features\n",
    "    constant_column = (df_random_row[constant_features_names].values[0]).astype(np.float32)\n",
    "    \n",
    "    # calculate the chemical component for kreislauf\n",
    "    kreislauf_column = (df_random_row[kreislauf_schrotte_names].values[0]).astype(np.float32)\n",
    "    kreislauf_chemical_table = df_chemi[chemi_names].iloc[len(kreislauf_schrotte_names)-1:]\n",
    "    chemi_component_kreislauf = (np.dot(kreislauf_column, kreislauf_chemical_table) /100.0).astype(np.float32)\n",
    "    \n",
    "    # calculate the chemical component for legierungen\n",
    "    legierung_column = (df_random_row[legierung_schrotte_names].values[0]).astype(np.float32)\n",
    "    legierung_chemical_table = df_chemi[chemi_names].iloc[len(fremd_schrotte_names):len(kreislauf_schrotte_names)-1]\n",
    "    chemi_component_legierung = (np.dot(legierung_column, legierung_chemical_table) /100.0).astype(np.float32)\n",
    "    \n",
    "    # calculate the chemical compoent for fremdschrotte\n",
    "    chemi_to_achieve_fremdschrotte = (np.abs(total_chemi_to_achieve - chemi_component_kreislauf - chemi_component_legierung)).astype(np.float32)\n",
    "    \n",
    "    return constant_column, kreislauf_column, legierung_column, chemi_to_achieve_fremdschrotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccbd9f90-783e-48db-9fee-8e52e0afeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_column, kreislauf_column, legierung_column, chemi_to_achieve_fremdschrotte = calculate_chemi_component(df, df_chemi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75898a05-eec6-45c4-8d90-11bc843831cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the chemical table\n",
    "# assume that every company's chemical elements for every schrott is identical\n",
    "def fremdschrott_chemi_table(df_chemi):\n",
    "    df_chemi_fremdschrott= df_chemi[chemi_names].iloc[:len(fremd_schrotte_names)]\n",
    "    fremdschrott_chemi = df_chemi_fremdschrott.T\n",
    "    n_times = 9\n",
    "    temp_dfs = []\n",
    "    \n",
    "    for col_name in fremdschrott_chemi.columns:\n",
    "        temp_df = fremdschrott_chemi[[col_name]].copy()\n",
    "        for i in range(1, n_times+1):\n",
    "            temp_df[f'{col_name}{i}'] = fremdschrott_chemi[col_name]\n",
    "        temp_dfs.append(temp_df)\n",
    "\n",
    "    fremdschrotte_chemi_table = pd.concat(temp_dfs, axis=1) / 100.0\n",
    "    \n",
    "    return fremdschrotte_chemi_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9418e-99d9-4843-b65e-6138ed694dd9",
   "metadata": {},
   "source": [
    "# Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f06804e-332e-45de-ba26-5d2a3dbe2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_fremdschrott = len(fremd_schrotte_names)\n",
    "length_company = 10\n",
    "\n",
    "total_variable_length = length_fremdschrott * length_company\n",
    "\n",
    "df_price_list = df_price[\"price\"].to_numpy()\n",
    "price_list = df_price_list[:total_variable_length]\n",
    "\n",
    "\n",
    "x_lower = np.zeros(total_variable_length)\n",
    "x_upper = np.ones(total_variable_length) * total_weight\n",
    "\n",
    "\n",
    "fremdschrotte_chemi_table = fremdschrott_chemi_table(df_chemi)\n",
    "# right hand side of equality constraints\n",
    "aeq = np.array(fremdschrotte_chemi_table)\n",
    "\n",
    "# start values\n",
    "x_start = np.zeros(total_variable_length)\n",
    "\n",
    "# scipy specific\n",
    "bounds = Bounds([0.0]*total_variable_length, [max(total_chemi_to_achieve)]*total_variable_length)\n",
    "\n",
    "# max iteration\n",
    "max_iter = 50 #1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50646757-0bc5-438a-afe3-5c549139cff7",
   "metadata": {},
   "source": [
    "## COBYQA + ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "99e3db10-a8c9-4ed9-ba17-a7c574ee4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xgboost and ann models\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model('models/XGB.json')\n",
    "\n",
    "ann_model = tf.keras.models.load_model(\"models/ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8205c01a-47b6-474e-8920-015cb09c6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for xgb prediction\n",
    "def f_xgb(x):\n",
    "    y = xgb_model.predict(xgb.DMatrix([x]))   #x1.reshape(1,-1))\n",
    "    return y.item()\n",
    "\n",
    "# function to calculate the total cost of xgboost version\n",
    "def sum_t3_xgb(x):\n",
    "    \"\"\"return sum of three objectives\"\"\"\n",
    "    summe = 0\n",
    "    #quantity = np.array([sum(g) for g in list(grouper(x, 10))])\n",
    "    quantity = np.array([sum(x[i:i+10]) for i in range(0, len(x), 10)])\n",
    "    for q in quantity:\n",
    "        if q <= 10.0:\n",
    "            summe += 0.0\n",
    "        elif q > 10.0 and q <= 50.0:\n",
    "            summe += 2.5 * (q-10) \n",
    "        else:\n",
    "            summe += 100.0\n",
    "\n",
    "        return summe\n",
    "\n",
    "# objective xgboost\n",
    "def objective(x, constant_column, kreislauf_column, legierung_column):\n",
    "    t1 = np.dot(x, price_list)\n",
    "    #list_fremdschrotte = [sum(g) for g in list(grouper(x, 10))]\n",
    "    list_fremdschrotte = [sum(x[i:i+10]) for i in range(0, len(x), 10)]\n",
    "    features = np.concatenate((constant_column, kreislauf_column, list_fremdschrotte, legierung_column))\n",
    "    t2 = f_xgb(features)\n",
    "    t3 = sum_t3_xgb(x)\n",
    "    return (t1 + t2 + t3).item()    \n",
    "\n",
    "# ann prediction    \n",
    "@tf.function\n",
    "def tf_ann(x,constant_column,kreislauf_column,legierung_column):\n",
    "    # x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "\n",
    "    list_fremdschrotte = tf.reduce_sum(tf.reshape(x,[-1,10]), axis=1)\n",
    "    x = tf.concat([constant_column, kreislauf_column, list_fremdschrotte, legierung_column], axis=0)\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    ann_pred = ann_model(x)\n",
    "    return ann_pred\n",
    "\n",
    "# function to calculate the logistic cost of tf version\n",
    "@tf.function\n",
    "def sum_t3_tf(x):\n",
    "    \"\"\"\n",
    "    X: tf.Tensor, the quantity of every scrap\n",
    "    \"\"\"\n",
    "    summe = tf.constant(0.0, dtype=tf.float32)\n",
    "    quantity = tf.reduce_sum(tf.reshape(x,[-1,10]), axis=1) #tf.convert_to_tensor([sum(g) for g in list(grouper(10, x))])\n",
    "\n",
    "    for q in quantity:\n",
    "        q = tf.reshape(q, ())\n",
    "        summe += tf.cond(q <= 10.0, \n",
    "                         lambda: 0.0, \n",
    "                         lambda: tf.cond(q > 10.0 and q <= 50.0, \n",
    "                                         lambda: 2.5 * (q - 10), \n",
    "                                         lambda: 100.0))\n",
    "    return summe\n",
    "\n",
    "\n",
    "# function for calculate the total cost, tf version\n",
    "@tf.function\n",
    "def objective_tf(x,constant_column,kreislauf_column,legierung_column):\n",
    "    price_list_tf = tf.convert_to_tensor(price_list, dtype=tf.float32)\n",
    "    t1 = tf.tensordot(x, price_list_tf,axes=1)\n",
    "    t2 = tf_ann(x,constant_column,kreislauf_column,legierung_column) \n",
    "    t3 = sum_t3_tf(x) \n",
    "    \n",
    "    #return t1 +t2 + t3\n",
    "    return t2\n",
    "\n",
    "# function to calculate the jacobian of tf \n",
    "#@tf.function\n",
    "def grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column):\n",
    "    x1 = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    constant_column = tf.convert_to_tensor(constant_column, dtype=tf.float32)\n",
    "    kreislauf_column = tf.convert_to_tensor(kreislauf_column, dtype=tf.float32)\n",
    "    legierung_column = tf.convert_to_tensor(legierung_column, dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x1)\n",
    "        t2 = objective_tf(x1,constant_column,kreislauf_column,legierung_column)\n",
    "        y = tape.jacobian(t2, x1)\n",
    "    return y\n",
    "    \n",
    "#function to calculate the jacobian of tf \n",
    "@tf.function\n",
    "def hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column):\n",
    "    x1 = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    constant_column = tf.convert_to_tensor(constant_column, dtype=tf.float32)\n",
    "    kreislauf_column = tf.convert_to_tensor(kreislauf_column, dtype=tf.float32)\n",
    "    legierung_column = tf.convert_to_tensor(legierung_column, dtype=tf.float32)\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x1)\n",
    "        obj_fun = objective_tf(x1,constant_column,kreislauf_column,legierung_column)\n",
    "        y = tape.gradient(obj_fun, x1)\n",
    "        h = tape.jacobian(y, x1)\n",
    "    \n",
    "    return y, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aac9e4cf-3139-4778-9200-0b0e36c54fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(160).astype(np.float32)\n",
    "\n",
    "constant_column, kreislauf_column, legierung_column, \\\n",
    "    chemi_to_achieve_fremdschrotte = calculate_chemi_component(df, df_chemi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ef98e8d3-0ff6-4342-8ec7-444ae551cf66",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\nNode: 'StatefulPartitionedCall'\nExpects arg[0] to be int64 but float is provided\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_tf_ann_49072]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf_ann(x,constant_column,kreislauf_column,legierung_column)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\nNode: 'StatefulPartitionedCall'\nExpects arg[0] to be int64 but float is provided\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_tf_ann_49072]"
     ]
    }
   ],
   "source": [
    "tf_ann(x,constant_column,kreislauf_column,legierung_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4fb98615-f1c4-4fdd-8267-4328bd18ad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[3503.3489]], dtype=float32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_tf(x,constant_column,kreislauf_column,legierung_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "491b8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "baa59830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Got error while pfor was converting op name: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf\"\n",
      "op: \"StatelessIf\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/Reshape_grad/Reshape_grad/Reshape\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4:1\"\n",
      "attr {\n",
      "  key: \"Tcond\"\n",
      "  value {\n",
      "    type: DT_BOOL\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_lower_using_switch_merge\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"else_branch\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_cond_false_38785_rewritten_grad_42167_rewritten_grad_43394_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"then_branch\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_cond_true_38784_rewritten_grad_42159_rewritten_grad_43384_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      " with inputs (<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack:1' shape=() dtype=bool>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/Reshape_grad/Reshape_grad/Reshape:0' shape=() dtype=float32>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack:1' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack:1' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack:1' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1:1' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2:1' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3:1' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4:1' shape=() dtype=variant>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack/pfor/TensorListPopBack:1' shape=() dtype=bool>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/Reshape_grad/Reshape_grad/Reshape/pfor/Reshape:0' shape=(None,) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4/pfor/TensorListPopBack:1' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False)]\n",
      "Here are the pfor conversion stack traces: Required handle data not set for <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/pfor/cond/PartitionedCall:1' shape=() dtype=variant>\n",
      "ERROR:tensorflow:name: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf\"\n",
      "op: \"StatelessIf\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/Reshape_grad/Reshape_grad/Reshape\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3:1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4:1\"\n",
      "attr {\n",
      "  key: \"Tcond\"\n",
      "  value {\n",
      "    type: DT_BOOL\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_lower_using_switch_merge\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"else_branch\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_cond_false_38785_rewritten_grad_42167_rewritten_grad_43394_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"then_branch\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_cond_true_38784_rewritten_grad_42159_rewritten_grad_43384_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2674/1972329697.py\", line 1, in <module>\n",
      "    hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 928, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 749, in _initialize\n",
      "    self._variable_creation_fn    # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 162, in _get_concrete_function_internal_garbage_collected\n",
      "    concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 157, in _maybe_define_concrete_function\n",
      "    return self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 360, in _maybe_define_function\n",
      "    concrete_function = self._create_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 284, in _create_concrete_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 645, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1258, in autograph_handler\n",
      "    return autograph.converted_call(\n",
      "    File \"/tmp/ipykernel_2674/558816245.py\", line 96, in hess_grad_f_ann_tf\n",
      "    y = tape.gradient(obj_fun, x1)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\", line 1112, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1086, in _backward_function_wrapper\n",
      "    return backward._call_flat(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1751, in _call_flat\n",
      "    forward_function, args_with_tangents = forward_backward.forward()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1278, in forward\n",
      "    forward_function = self._functions.forward(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1010, in forward\n",
      "    self._forward_and_backward_functions(inference_args, input_tangents))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1234, in _forward_and_backward_functions\n",
      "    self._build_functions_for_outputs(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 730, in _build_functions_for_outputs\n",
      "    gradients_wrt_inputs = gradients_util._GradientsHelper(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 695, in _GradientsHelper\n",
      "    in_grads = _MaybeCompile(grad_scope, op, func_call,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 329, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 696, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 547, in _rewrite_forward_and_call_backward\n",
      "    forward_function, backwards_function = self.forward_backward(len(doutputs))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 480, in forward_backward\n",
      "    forward, backward = self._construct_forward_backward(num_doutputs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 523, in _construct_forward_backward\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 514, in _backprop_function\n",
      "    return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 695, in _GradientsHelper\n",
      "    in_grads = _MaybeCompile(grad_scope, op, func_call,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 329, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 696, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 393, in _WhileGrad\n",
      "    body_grad_graph, args = _create_grad_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 695, in _create_grad_func\n",
      "    grad_func_graph = func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 697, in <lambda>\n",
      "    lambda *args: _grad_fn(ys, xs, args, body_graph),\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 753, in _grad_fn\n",
      "    grad_outs = gradients_util._GradientsHelper(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 695, in _GradientsHelper\n",
      "    in_grads = _MaybeCompile(grad_scope, op, func_call,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 329, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 696, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\", line 180, in _IfGrad\n",
      "    outputs = _build_cond(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\", line 296, in _build_cond\n",
      "    tensors = util.run_as_function_for_tape_gradients(_make_op, cond_inputs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_util_v2.py\", line 376, in run_as_function_for_tape_gradients\n",
      "    return make_op(inputs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\", line 270, in _make_op\n",
      "    if_op, tensors = util.get_op_and_outputs(op_fn(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_functional_ops.py\", line 903, in stateless_if\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 1044, in _create_op_internal\n",
      "    return super(_WhileBodyGradFuncGraph, self)._create_op_internal(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 749, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n",
      "    ret = Operation(\n",
      "\n",
      "ERROR:tensorflow:Got error while pfor was converting op name: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad\"\n",
      "op: \"StatelessWhile\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/grad_counter\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad/while/maximum_iterations\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad\"\n",
      "input: \"gradients/grad_ys_1\"\n",
      "input: \"gradients/gradients/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack_grad/TensorListFromTensor\"\n",
      "input: \"gradients/grad_ys_2\"\n",
      "input: \"gradients/grad_ys_3\"\n",
      "input: \"gradients/grad_ys_4\"\n",
      "input: \"gradients/grad_ys_5\"\n",
      "input: \"gradients/grad_ys_6\"\n",
      "input: \"gradients/grad_ys_7\"\n",
      "input: \"gradients/grad_ys_8\"\n",
      "input: \"gradients/grad_ys_9\"\n",
      "input: \"gradients/grad_ys_10\"\n",
      "input: \"gradients/grad_ys_11\"\n",
      "input: \"gradients/grad_ys_12\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_2\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_3\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_4\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_5\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_6\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_2/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_3/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_4/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListElementShape_0/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListLength_0/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListSetItem/TensorListPopBack_1/accumulator:0\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_lower_using_switch_merge\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_num_original_outputs\"\n",
      "  value {\n",
      "    i: 36\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_stateful_parallelism\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"body\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_body_38760_rewritten_grad_42139_rewritten_grad_43321_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"cond\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_cond_38759_rewritten_grad_42248_rewritten_grad_43501_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"parallel_iterations\"\n",
      "  value {\n",
      "    i: 10\n",
      "  }\n",
      "}\n",
      " with inputs (<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/grad_counter:0' shape=() dtype=int32>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad/while/maximum_iterations:0' shape=() dtype=int32>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad:0' shape=() dtype=int32>, <tf.Tensor 'gradients/grad_ys_1:0' shape=() dtype=float32>, <tf.Tensor 'gradients/gradients/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack_grad/TensorListFromTensor:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_2:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_3:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_4:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_5:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_6:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_7:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_8:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_9:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_10:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_11:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_12:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_1:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_2:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_3:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_4:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_5:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_6:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_2/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_3/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_4/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4_1/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListElementShape_0/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListLength_0/accumulator:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListSetItem/TensorListPopBack_1/accumulator:0' shape=() dtype=variant>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/grad_counter/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_14:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_15:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_1/pfor/Identity:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack_grad/TensorListFromTensor/pfor/TensorListFromTensor:0' shape=() dtype=variant>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_2/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_3/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_4/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_5/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_6/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_7/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_8/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_9/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_10/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_11/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_12/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_16:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_17:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_18:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_19:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_20:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_21:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_2/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_3/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_4/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListElementShape_0/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListLength_0/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListSetItem/TensorListPopBack_1/accumulator/pfor/EmptyTensorList:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False)]\n",
      "Here are the pfor conversion stack traces: in user code:\n",
      "\n",
      "\n",
      "    ValueError: Required handle data not set for <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/pfor/cond/PartitionedCall:1' shape=() dtype=variant>\n",
      "\n",
      "ERROR:tensorflow:name: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad\"\n",
      "op: \"StatelessWhile\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/grad_counter\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad/while/maximum_iterations\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad\"\n",
      "input: \"gradients/grad_ys_1\"\n",
      "input: \"gradients/gradients/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack_grad/TensorListFromTensor\"\n",
      "input: \"gradients/grad_ys_2\"\n",
      "input: \"gradients/grad_ys_3\"\n",
      "input: \"gradients/grad_ys_4\"\n",
      "input: \"gradients/grad_ys_5\"\n",
      "input: \"gradients/grad_ys_6\"\n",
      "input: \"gradients/grad_ys_7\"\n",
      "input: \"gradients/grad_ys_8\"\n",
      "input: \"gradients/grad_ys_9\"\n",
      "input: \"gradients/grad_ys_10\"\n",
      "input: \"gradients/grad_ys_11\"\n",
      "input: \"gradients/grad_ys_12\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_1\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_2\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_3\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_4\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_5\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_6\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_4_grad/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_5_grad/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_2/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_3/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf_4/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/TensorListPushBack_3_grad/TensorListPopBack_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_1_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_2_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_3_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/TensorListPopBack_4_1/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListElementShape_0/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/while_grad/while_grad_grad_grad/gradients/gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListGetItem_grad/TensorListLength_0/accumulator:0\"\n",
      "input: \"gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/TensorArrayV2Read/TensorListGetItem_grad/TensorListSetItem_grad/TensorListSetItem/TensorListPopBack_1/accumulator:0\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_lower_using_switch_merge\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_num_original_outputs\"\n",
      "  value {\n",
      "    i: 36\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_stateful_parallelism\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"body\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_body_38760_rewritten_grad_42139_rewritten_grad_43321_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"cond\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"while_cond_38759_rewritten_grad_42248_rewritten_grad_43501_rewritten\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"parallel_iterations\"\n",
      "  value {\n",
      "    i: 10\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2674/1972329697.py\", line 1, in <module>\n",
      "    hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 928, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 749, in _initialize\n",
      "    self._variable_creation_fn    # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 162, in _get_concrete_function_internal_garbage_collected\n",
      "    concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 157, in _maybe_define_concrete_function\n",
      "    return self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 360, in _maybe_define_function\n",
      "    concrete_function = self._create_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 284, in _create_concrete_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 645, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1258, in autograph_handler\n",
      "    return autograph.converted_call(\n",
      "    File \"/tmp/ipykernel_2674/558816245.py\", line 96, in hess_grad_f_ann_tf\n",
      "    y = tape.gradient(obj_fun, x1)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\", line 1112, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1086, in _backward_function_wrapper\n",
      "    return backward._call_flat(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1751, in _call_flat\n",
      "    forward_function, args_with_tangents = forward_backward.forward()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1278, in forward\n",
      "    forward_function = self._functions.forward(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1010, in forward\n",
      "    self._forward_and_backward_functions(inference_args, input_tangents))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1234, in _forward_and_backward_functions\n",
      "    self._build_functions_for_outputs(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 730, in _build_functions_for_outputs\n",
      "    gradients_wrt_inputs = gradients_util._GradientsHelper(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 695, in _GradientsHelper\n",
      "    in_grads = _MaybeCompile(grad_scope, op, func_call,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 329, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 696, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 547, in _rewrite_forward_and_call_backward\n",
      "    forward_function, backwards_function = self.forward_backward(len(doutputs))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 480, in forward_backward\n",
      "    forward, backward = self._construct_forward_backward(num_doutputs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 523, in _construct_forward_backward\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 514, in _backprop_function\n",
      "    return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 695, in _GradientsHelper\n",
      "    in_grads = _MaybeCompile(grad_scope, op, func_call,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 329, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 696, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 453, in _WhileGrad\n",
      "    outputs = _build_while_op(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 508, in _build_while_op\n",
      "    return util.run_as_function_for_tape_gradients(_make_op, loop_vars)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_util_v2.py\", line 376, in run_as_function_for_tape_gradients\n",
      "    return make_op(inputs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\", line 484, in _make_op\n",
      "    while_op, tensors = util.get_op_and_outputs(op_fn(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_functional_ops.py\", line 1007, in stateless_while\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 749, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n",
      "    ret = Operation(\n",
      "\n",
      "ERROR:tensorflow:Got error while pfor was converting op name: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradients/grad_ys_0\"\n",
      "input: \"gradients/grad_ys_15\"\n",
      "input: \"gradients/grad_ys_16\"\n",
      "input: \"gradients/grad_ys_17\"\n",
      "input: \"gradients/grad_ys_18\"\n",
      "input: \"gradients/grad_ys_19\"\n",
      "input: \"gradients/grad_ys_20\"\n",
      "input: \"gradients/grad_ys_21\"\n",
      "input: \"gradients/grad_ys_22\"\n",
      "input: \"gradients/grad_ys_23\"\n",
      "input: \"gradients/grad_ys_24\"\n",
      "input: \"gradients/grad_ys_25\"\n",
      "input: \"gradients/grad_ys_26\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_1\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_2\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_3\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_4\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_5\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_6\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_7\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_8\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_collective_manager_ids\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__forward___backward___backward_sum_t3_tf_42129_43274_45608\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      " with inputs (<tf.Tensor 'gradients/grad_ys_0:0' shape=(160,) dtype=float32>, <tf.Tensor 'gradients/grad_ys_15:0' shape=() dtype=float32>, <tf.Tensor 'gradients/grad_ys_16:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_17:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_18:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_19:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_20:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_21:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_22:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_23:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_24:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_25:0' shape=() dtype=variant>, <tf.Tensor 'gradients/grad_ys_26:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8:0' shape=(2,) dtype=int32>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_1:0' shape=() dtype=int32>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_2:0' shape=() dtype=int32>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_3:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_4:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_5:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_6:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_7:0' shape=() dtype=variant>, <tf.Tensor 'gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_8:0' shape=() dtype=variant>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_0/pfor/Identity:0' shape=(160, 160) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_15/pfor/Identity:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_16/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_17/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_18/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_19/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_20/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_21/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_22/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_23/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_24/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_25/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_26/pfor/Identity:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_37:0' shape=(2,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_38:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_39:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_40:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_41:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_42:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_43:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_44:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_45:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False)]\n",
      "Here are the pfor conversion stack traces: in user code:\n",
      "\n",
      "\n",
      "    ValueError: Required handle data not set for <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/pfor/cond/PartitionedCall:1' shape=() dtype=variant>\n",
      "\n",
      "ERROR:tensorflow:name: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradients/grad_ys_0\"\n",
      "input: \"gradients/grad_ys_15\"\n",
      "input: \"gradients/grad_ys_16\"\n",
      "input: \"gradients/grad_ys_17\"\n",
      "input: \"gradients/grad_ys_18\"\n",
      "input: \"gradients/grad_ys_19\"\n",
      "input: \"gradients/grad_ys_20\"\n",
      "input: \"gradients/grad_ys_21\"\n",
      "input: \"gradients/grad_ys_22\"\n",
      "input: \"gradients/grad_ys_23\"\n",
      "input: \"gradients/grad_ys_24\"\n",
      "input: \"gradients/grad_ys_25\"\n",
      "input: \"gradients/grad_ys_26\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_1\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_2\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_3\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_4\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_5\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_6\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_7\"\n",
      "input: \"gradients/gradients/PartitionedCall_grad/PartitionedCall_8_grad/gradients/PartitionedCall_grad/PartitionedCall_8_8\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_collective_manager_ids\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__forward___backward___backward_sum_t3_tf_42129_43274_45608\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2674/1972329697.py\", line 1, in <module>\n",
      "    hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 928, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 749, in _initialize\n",
      "    self._variable_creation_fn    # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 162, in _get_concrete_function_internal_garbage_collected\n",
      "    concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 157, in _maybe_define_concrete_function\n",
      "    return self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 360, in _maybe_define_function\n",
      "    concrete_function = self._create_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 284, in _create_concrete_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 645, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1258, in autograph_handler\n",
      "    return autograph.converted_call(\n",
      "    File \"/tmp/ipykernel_2674/558816245.py\", line 96, in hess_grad_f_ann_tf\n",
      "    y = tape.gradient(obj_fun, x1)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\", line 1112, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1086, in _backward_function_wrapper\n",
      "    return backward._call_flat(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1751, in _call_flat\n",
      "    forward_function, args_with_tangents = forward_backward.forward()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1278, in forward\n",
      "    forward_function = self._functions.forward(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1010, in forward\n",
      "    self._forward_and_backward_functions(inference_args, input_tangents))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1239, in _forward_and_backward_functions\n",
      "    self._build_functions_for_outputs(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 730, in _build_functions_for_outputs\n",
      "    gradients_wrt_inputs = gradients_util._GradientsHelper(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 695, in _GradientsHelper\n",
      "    in_grads = _MaybeCompile(grad_scope, op, func_call,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 329, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\", line 696, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 586, in _rewrite_forward_and_call_backward\n",
      "    return backwards_function._call_flat(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1759, in _call_flat\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 406, in call\n",
      "    outputs = functional_ops.partitioned_call(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/functional_ops.py\", line 1222, in partitioned_call\n",
      "    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py\", line 561, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3736, in create_op\n",
      "    return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 749, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n",
      "    ret = Operation(\n",
      "\n",
      "ERROR:tensorflow:Got error while pfor was converting op name: \"loop_body/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradient_tape/Reshape\"\n",
      "input: \"loop_body/zeros\"\n",
      "input: \"loop_body/zeros_1\"\n",
      "input: \"loop_body/zeros_2\"\n",
      "input: \"loop_body/zeros_3\"\n",
      "input: \"loop_body/zeros_4\"\n",
      "input: \"loop_body/zeros_5\"\n",
      "input: \"loop_body/zeros_6\"\n",
      "input: \"loop_body/zeros_7\"\n",
      "input: \"loop_body/zeros_8\"\n",
      "input: \"loop_body/zeros_9\"\n",
      "input: \"loop_body/zeros_10\"\n",
      "input: \"loop_body/zeros_11\"\n",
      "input: \"loop_body/zeros_12\"\n",
      "input: \"loop_body/zeros_13\"\n",
      "input: \"loop_body/zeros_15\"\n",
      "input: \"loop_body/zeros_like\"\n",
      "input: \"loop_body/zeros_like_1\"\n",
      "input: \"loop_body/zeros_like_2\"\n",
      "input: \"loop_body/zeros_like_3\"\n",
      "input: \"loop_body/zeros_like_6\"\n",
      "input: \"loop_body/zeros_like_7\"\n",
      "input: \"loop_body/zeros_like_8\"\n",
      "input: \"loop_body/zeros_like_9\"\n",
      "input: \"loop_body/zeros_like_10\"\n",
      "input: \"loop_body/zeros_like_11\"\n",
      "input: \"loop_body/zeros_like_12\"\n",
      "input: \"loop_body/zeros_18\"\n",
      "input: \"loop_body/zeros_19\"\n",
      "input: \"PartitionedCall:7\"\n",
      "input: \"PartitionedCall:8\"\n",
      "input: \"PartitionedCall:9\"\n",
      "input: \"PartitionedCall:10\"\n",
      "input: \"PartitionedCall:11\"\n",
      "input: \"PartitionedCall:12\"\n",
      "input: \"PartitionedCall:13\"\n",
      "input: \"PartitionedCall:14\"\n",
      "input: \"PartitionedCall:15\"\n",
      "input: \"PartitionedCall:21\"\n",
      "input: \"PartitionedCall:22\"\n",
      "input: \"PartitionedCall:23\"\n",
      "input: \"PartitionedCall:24\"\n",
      "input: \"PartitionedCall:25\"\n",
      "input: \"PartitionedCall:26\"\n",
      "input: \"PartitionedCall:27\"\n",
      "input: \"PartitionedCall:28\"\n",
      "input: \"PartitionedCall:32\"\n",
      "input: \"PartitionedCall:33\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__forward___backward___backward_objective_tf_42397_43627_45881\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      " with inputs (<tf.Tensor 'gradient_tape/Reshape:0' shape=(160,) dtype=float32>, <tf.Tensor 'loop_body/zeros:0' shape=(82, 50) dtype=float32>, <tf.Tensor 'loop_body/zeros_1:0' shape=(50,) dtype=float32>, <tf.Tensor 'loop_body/zeros_2:0' shape=(50, 100) dtype=float32>, <tf.Tensor 'loop_body/zeros_3:0' shape=(100,) dtype=float32>, <tf.Tensor 'loop_body/zeros_4:0' shape=(100, 1) dtype=float32>, <tf.Tensor 'loop_body/zeros_5:0' shape=(1,) dtype=float32>, <tf.Tensor 'loop_body/zeros_6:0' shape=(1, 50) dtype=float32>, <tf.Tensor 'loop_body/zeros_7:0' shape=(1, 82) dtype=float32>, <tf.Tensor 'loop_body/zeros_8:0' shape=(1, 100) dtype=float32>, <tf.Tensor 'loop_body/zeros_9:0' shape=(1, 50) dtype=float32>, <tf.Tensor 'loop_body/zeros_10:0' shape=(1, 1) dtype=float32>, <tf.Tensor 'loop_body/zeros_11:0' shape=(1, 100) dtype=float32>, <tf.Tensor 'loop_body/zeros_12:0' shape=(50, 100) dtype=float32>, <tf.Tensor 'loop_body/zeros_13:0' shape=(100, 1) dtype=float32>, <tf.Tensor 'loop_body/zeros_15:0' shape=() dtype=float32>, <tf.Tensor 'loop_body/zeros_like:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_1:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_2:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_3:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_6:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_7:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_8:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_9:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_10:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_11:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_like_12:0' shape=() dtype=variant>, <tf.Tensor 'loop_body/zeros_18:0' shape=(160, 1) dtype=float32>, <tf.Tensor 'loop_body/zeros_19:0' shape=(1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:7' shape=(1, 50) dtype=float32>, <tf.Tensor 'PartitionedCall:8' shape=(1, 82) dtype=float32>, <tf.Tensor 'PartitionedCall:9' shape=(1, 100) dtype=float32>, <tf.Tensor 'PartitionedCall:10' shape=(1, 50) dtype=float32>, <tf.Tensor 'PartitionedCall:11' shape=(1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:12' shape=(1, 100) dtype=float32>, <tf.Tensor 'PartitionedCall:13' shape=(50, 100) dtype=float32>, <tf.Tensor 'PartitionedCall:14' shape=(100, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:15' shape=(2,) dtype=int32>, <tf.Tensor 'PartitionedCall:21' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:22' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:23' shape=() dtype=variant>, <tf.Tensor 'PartitionedCall:24' shape=() dtype=variant>, <tf.Tensor 'PartitionedCall:25' shape=() dtype=variant>, <tf.Tensor 'PartitionedCall:26' shape=() dtype=variant>, <tf.Tensor 'PartitionedCall:27' shape=() dtype=variant>, <tf.Tensor 'PartitionedCall:28' shape=() dtype=variant>, <tf.Tensor 'PartitionedCall:32' shape=(160, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:33' shape=(1, 1) dtype=float32>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradient_tape/Reshape/pfor/Reshape:0' shape=(160, 160) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros:0' shape=(82, 50) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_1:0' shape=(50,) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_2:0' shape=(50, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_3:0' shape=(100,) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_4:0' shape=(100, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_5:0' shape=(1,) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_6:0' shape=(1, 50) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_7:0' shape=(1, 82) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_8:0' shape=(1, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_9:0' shape=(1, 50) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_10:0' shape=(1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_11:0' shape=(1, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_12:0' shape=(50, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_13:0' shape=(100, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_15:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_1:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_2:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_3:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_6:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_7:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_8:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_9:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_10:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_11:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_like_12:0' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_18:0' shape=(160, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_19:0' shape=(1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:7' shape=(1, 50) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:8' shape=(1, 82) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:9' shape=(1, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:10' shape=(1, 50) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:11' shape=(1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:12' shape=(1, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:13' shape=(50, 100) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:14' shape=(100, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:15' shape=(2,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:21' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:22' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:23' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:24' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:25' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:26' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:27' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:28' shape=() dtype=variant>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:32' shape=(160, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:33' shape=(1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False)]\n",
      "Here are the pfor conversion stack traces: in user code:\n",
      "\n",
      "\n",
      "    ValueError: Required handle data not set for <tf.Tensor 'gradients/gradients/while_grad/while_grad_grad/gradients/gradients/while_grad/gradients/while/cond_grad/StatelessIf_grad/StatelessIf/pfor/cond/PartitionedCall:1' shape=() dtype=variant>\n",
      "\n",
      "ERROR:tensorflow:name: \"loop_body/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradient_tape/Reshape\"\n",
      "input: \"loop_body/zeros\"\n",
      "input: \"loop_body/zeros_1\"\n",
      "input: \"loop_body/zeros_2\"\n",
      "input: \"loop_body/zeros_3\"\n",
      "input: \"loop_body/zeros_4\"\n",
      "input: \"loop_body/zeros_5\"\n",
      "input: \"loop_body/zeros_6\"\n",
      "input: \"loop_body/zeros_7\"\n",
      "input: \"loop_body/zeros_8\"\n",
      "input: \"loop_body/zeros_9\"\n",
      "input: \"loop_body/zeros_10\"\n",
      "input: \"loop_body/zeros_11\"\n",
      "input: \"loop_body/zeros_12\"\n",
      "input: \"loop_body/zeros_13\"\n",
      "input: \"loop_body/zeros_15\"\n",
      "input: \"loop_body/zeros_like\"\n",
      "input: \"loop_body/zeros_like_1\"\n",
      "input: \"loop_body/zeros_like_2\"\n",
      "input: \"loop_body/zeros_like_3\"\n",
      "input: \"loop_body/zeros_like_6\"\n",
      "input: \"loop_body/zeros_like_7\"\n",
      "input: \"loop_body/zeros_like_8\"\n",
      "input: \"loop_body/zeros_like_9\"\n",
      "input: \"loop_body/zeros_like_10\"\n",
      "input: \"loop_body/zeros_like_11\"\n",
      "input: \"loop_body/zeros_like_12\"\n",
      "input: \"loop_body/zeros_18\"\n",
      "input: \"loop_body/zeros_19\"\n",
      "input: \"PartitionedCall:7\"\n",
      "input: \"PartitionedCall:8\"\n",
      "input: \"PartitionedCall:9\"\n",
      "input: \"PartitionedCall:10\"\n",
      "input: \"PartitionedCall:11\"\n",
      "input: \"PartitionedCall:12\"\n",
      "input: \"PartitionedCall:13\"\n",
      "input: \"PartitionedCall:14\"\n",
      "input: \"PartitionedCall:15\"\n",
      "input: \"PartitionedCall:21\"\n",
      "input: \"PartitionedCall:22\"\n",
      "input: \"PartitionedCall:23\"\n",
      "input: \"PartitionedCall:24\"\n",
      "input: \"PartitionedCall:25\"\n",
      "input: \"PartitionedCall:26\"\n",
      "input: \"PartitionedCall:27\"\n",
      "input: \"PartitionedCall:28\"\n",
      "input: \"PartitionedCall:32\"\n",
      "input: \"PartitionedCall:33\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_VARIANT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__forward___backward___backward_objective_tf_42397_43627_45881\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2674/1972329697.py\", line 1, in <module>\n",
      "    hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 928, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 749, in _initialize\n",
      "    self._variable_creation_fn    # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 162, in _get_concrete_function_internal_garbage_collected\n",
      "    concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 157, in _maybe_define_concrete_function\n",
      "    return self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 360, in _maybe_define_function\n",
      "    concrete_function = self._create_concrete_function(args, kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 284, in _create_concrete_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1283, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 645, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1258, in autograph_handler\n",
      "    return autograph.converted_call(\n",
      "    File \"/tmp/ipykernel_2674/558816245.py\", line 97, in hess_grad_f_ann_tf\n",
      "    h = tape.jacobian(y, x1)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\", line 1216, in jacobian\n",
      "    output = pfor_ops.pfor(loop_fn, target_size,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 214, in pfor\n",
      "    outputs = f()\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 193, in f\n",
      "    return _pfor_impl(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 295, in _pfor_impl\n",
      "    loop_fn_outputs = f(loop_var)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\", line 1206, in loop_fn\n",
      "    return self.gradient(y, flat_sources,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\", line 1112, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1086, in _backward_function_wrapper\n",
      "    return backward._call_flat(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1759, in _call_flat\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 406, in call\n",
      "    outputs = functional_ops.partitioned_call(\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/functional_ops.py\", line 1222, in partitioned_call\n",
      "    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py\", line 561, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3736, in create_op\n",
      "    return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 749, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    File \"/home/cican/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n",
      "    ret = Operation(\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_2674/558816245.py\", line 97, in hess_grad_f_ann_tf  *\n        h = tape.jacobian(y, x1)\n\n    ValueError: Encountered an exception while vectorizing the jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filepvy7voip.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__hess_grad_f_ann_tf\u001b[0;34m(x, constant_column, kreislauf_column, legierung_column)\u001b[0m\n\u001b[1;32m     16\u001b[0m     obj_fun \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(objective_tf), (ag__\u001b[39m.\u001b[39mld(x1), ag__\u001b[39m.\u001b[39mld(constant_column), ag__\u001b[39m.\u001b[39mld(kreislauf_column), ag__\u001b[39m.\u001b[39mld(legierung_column)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     17\u001b[0m     y \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(obj_fun), ag__\u001b[39m.\u001b[39mld(x1)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 18\u001b[0m     h \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mjacobian, (ag__\u001b[39m.\u001b[39mld(y), ag__\u001b[39m.\u001b[39mld(x1)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     19\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_2674/558816245.py\", line 97, in hess_grad_f_ann_tf  *\n        h = tape.jacobian(y, x1)\n\n    ValueError: Encountered an exception while vectorizing the jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.\n"
     ]
    }
   ],
   "source": [
    "hess_grad_f_ann_tf(x,constant_column,kreislauf_column,legierung_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e24c7958-8d3e-4ab5-a12b-65fbae72d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cobyqa(constant_column, kreislauf_column, legierung_column, beq):\n",
    "    # Wrap the objective function with a lambda to include the constant variables\n",
    "    wrapped_objective = lambda x: objective(x, constant_column, kreislauf_column, legierung_column)\n",
    "    \n",
    "    start_cobyqa = time.time()\n",
    "    res_cobyqa = cobyqa.minimize(wrapped_objective, x0=x_start, xl=x_lower, xu=x_upper,\n",
    "                                  aeq=aeq, beq=beq, options={\"disp\": False, \"maxiter\": max_iter})\n",
    "    end_cobyqa = time.time()\n",
    "\n",
    "    elapsed_time_cobyqa = end_cobyqa - start_cobyqa\n",
    "    \n",
    "    c_violation = (np.dot(aeq, res_cobyqa.x) - beq).tolist()\n",
    "\n",
    "    return res_cobyqa.x, res_cobyqa.fun, c_violation, elapsed_time_cobyqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ad1cf396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_trust_region(constant_column, kreislauf_column, legierung_column, beq):\n",
    "    # Wrap the objective and gradient functions with lambda functions\n",
    "    \n",
    "    wrapped_objective_tf = lambda x: objective_tf(x.astype(np.float32), constant_column, kreislauf_column, legierung_column)\n",
    "    wrapped_grad_f_ann_tf = lambda x: hess_grad_f_ann_tf(x.astype(np.float32), constant_column, kreislauf_column, legierung_column)\n",
    "    # jac, hess = wrapped_grad_f_ann_tf(x.astype(np.float32))\n",
    "    # j = tf.expand_dims(jac, axis=0)\n",
    "    # h = tf.expand_dims(hess, axis=0)\n",
    "    \n",
    "    def equality_fun(x):\n",
    "        return np.dot(aeq, x) - beq \n",
    "    \n",
    "    eq_cons = {'type': 'eq','fun' : equality_fun}\n",
    "    \n",
    "    start = time.time()\n",
    "    result = minimize(fun=wrapped_objective_tf, x0=x_start, jac=j, hess=h, constraints=[eq_cons], method='trust-constr',\n",
    "                      options={'disp': False, 'maxiter':max_iter, 'ftol':1e-9}, bounds=bounds, tol=1e-9)\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    c_violation = (np.dot(aeq, result.x) - beq).tolist()\n",
    "    elapsed_time = end - start\n",
    "    return result.x, result.fun, c_violation, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "81da86f9-4871-41ed-b00a-742ccda86304",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SLSQP\n",
    "def optimize_grad(constant_column, kreislauf_column, legierung_column, beq):\n",
    "    # Wrap the objective and gradient functions with lambda functions\n",
    "    \n",
    "    wrapped_objective_tf = lambda x: objective_tf(x.astype(np.float32), constant_column, kreislauf_column, legierung_column)\n",
    "    wrapped_grad_f_ann_tf = lambda x: grad_f_ann_tf(x.astype(np.float32), constant_column, kreislauf_column, legierung_column)\n",
    "        \n",
    "    def equality_fun(x):\n",
    "        return np.dot(aeq, x) - beq \n",
    "    \n",
    "    eq_cons = {'type': 'eq','fun' : equality_fun}\n",
    "    \n",
    "    start = time.time()\n",
    "    result = minimize(fun=wrapped_objective_tf, x0=x_start, jac=wrapped_grad_f_ann_tf, constraints=[eq_cons], method='SLSQP',\n",
    "                      options={'disp': False, 'maxiter':max_iter, 'ftol':1e-9}, bounds=bounds, tol=1e-9)\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    c_violation = (np.dot(aeq, result.x) - beq).tolist()\n",
    "    elapsed_time = end - start\n",
    "    return result.x, result.fun, c_violation, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "db4448bd-b2eb-4bb0-b861-be129ebfc440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Optimizing for 0 COBYQA iteration #################\n",
      "################# Optimizing for 0 trust region iteration #################\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert '2-point' to EagerTensor of dtype float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[274], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m################# trust region ####################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m################# Optimizing for \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m trust region iteration #################\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m x_trst, loss_trst, c_violation_trust, elapsed_time_trust \u001b[39m=\u001b[39m optimize_trust_region(constant_column, kreislauf_column, legierung_column, beq)\n\u001b[1;32m     14\u001b[0m results_current[\u001b[39m'\u001b[39m\u001b[39mtrust\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m {}\n\u001b[1;32m     15\u001b[0m results_current[\u001b[39m'\u001b[39m\u001b[39mtrust\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mx_min\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m x_trst\u001b[39m.\u001b[39mtolist()\n",
      "Cell \u001b[0;32mIn[272], line 16\u001b[0m, in \u001b[0;36moptimize_trust_region\u001b[0;34m(constant_column, kreislauf_column, legierung_column, beq)\u001b[0m\n\u001b[1;32m     13\u001b[0m eq_cons \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39meq\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m : equality_fun}\n\u001b[1;32m     15\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 16\u001b[0m result \u001b[39m=\u001b[39m minimize(fun\u001b[39m=\u001b[39;49mwrapped_objective_tf, x0\u001b[39m=\u001b[39;49mx_start, jac\u001b[39m=\u001b[39;49mj, hess\u001b[39m=\u001b[39;49mh, constraints\u001b[39m=\u001b[39;49m[eq_cons], method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrust-constr\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m                   options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mdisp\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m'\u001b[39;49m:max_iter, \u001b[39m'\u001b[39;49m\u001b[39mftol\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m1e-9\u001b[39;49m}, bounds\u001b[39m=\u001b[39;49mbounds, tol\u001b[39m=\u001b[39;49m\u001b[39m1e-9\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     21\u001b[0m c_violation \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mdot(aeq, result\u001b[39m.\u001b[39mx) \u001b[39m-\u001b[39m beq)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:580\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    578\u001b[0m     fun \u001b[39m=\u001b[39m MemoizeJac(fun)\n\u001b[1;32m    579\u001b[0m     jac \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39mderivative\n\u001b[0;32m--> 580\u001b[0m \u001b[39melif\u001b[39;00m (jac \u001b[39min\u001b[39;49;00m FD_METHODS \u001b[39mand\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       meth \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrust-constr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mslsqp\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    582\u001b[0m     \u001b[39m# finite differences with relative step\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrust-constr\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    585\u001b[0m     \u001b[39m# default jac calculation for this method\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert '2-point' to EagerTensor of dtype float"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(2):\n",
    "    print(f\"################# Optimizing for {i} COBYQA iteration #################\")\n",
    "    constant_column, kreislauf_column, legierung_column, \\\n",
    "    chemi_to_achieve_fremdschrotte = calculate_chemi_component(df, df_chemi)\n",
    "    \n",
    "    beq = chemi_to_achieve_fremdschrotte\n",
    "    \n",
    "    results_current = {'i': i, 'beq': beq.tolist()}\n",
    "    \n",
    "    ################# trust region ####################\n",
    "    print(f\"################# Optimizing for {i} trust region iteration #################\")\n",
    "    x_trst, loss_trst, c_violation_trust, elapsed_time_trust = optimize_trust_region(constant_column, kreislauf_column, legierung_column, beq)\n",
    "    results_current['trust'] = {}\n",
    "    results_current['trust']['x_min'] = x_trst.tolist()\n",
    "    results_current['trust']['loss'] = objective(x_trst,constant_column, kreislauf_column, legierung_column)\n",
    "    results_current['trust']['c_violation'] = c_violation_trust\n",
    "    results_current['trust']['time'] = elapsed_time_trust\n",
    "    \n",
    "    if np.sum(np.abs(c_violation_ann)) / np.sum(beq) > 0.05:\n",
    "        results_current['trust']['is_x_accept'] = 'no'\n",
    "    else:\n",
    "        results_current['trust']['is_x_accept'] = 'yes'\n",
    "\n",
    "    \n",
    "    ############### cobyqa ##########################\n",
    "\n",
    "    x, loss, c_violation, elapsed_time_cobyqa = optimize_cobyqa(constant_column, kreislauf_column, legierung_column, beq)\n",
    "    results_current['cobyqa'] = {}\n",
    "    results_current['cobyqa']['x_min'] = x.tolist()\n",
    "    results_current['cobyqa']['loss'] = loss\n",
    "    results_current['cobyqa']['c_violation'] = c_violation\n",
    "    results_current['cobyqa']['time'] = elapsed_time_cobyqa\n",
    "    ###################################################\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ############## ann ###############################\n",
    "    \n",
    "    print(f\"################# Optimizing for {i} ann iteration #################\")\n",
    "    x_ann, loss_ann, c_violation_ann, elapsed_time_ann = optimize_grad(constant_column, kreislauf_column, legierung_column, beq)\n",
    "    results_current['ann'] = {}\n",
    "    results_current['ann']['x_min'] = x_ann.tolist()\n",
    "    results_current['ann']['loss'] = objective(x_ann,constant_column, kreislauf_column, legierung_column)\n",
    "    results_current['ann']['c_violation'] = c_violation_ann\n",
    "    results_current['ann']['time'] = elapsed_time_ann\n",
    "    \n",
    "    if np.sum(np.abs(c_violation_ann)) / np.sum(beq) > 0.05:\n",
    "        results_current['ann']['is_x_accept'] = 'no'\n",
    "    else:\n",
    "        results_current['ann']['is_x_accept'] = 'yes'\n",
    "    \n",
    "    results.append(results_current)\n",
    "    with open('optimization/results2.json', 'w') as file:\n",
    "        json.dump(results, file)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c1f1e-253e-40ea-b640-93fb20cc64f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
